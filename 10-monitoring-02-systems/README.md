# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

+ Метрики использования процессора (CPU): важный показатель, так как в ТЗ указано, что вычисления загружают ЦПУ. Можно отслеживать такие метрики, как среднее использование процессора, пиковое использование и время работы без прерываний

+ Метрики использования памяти: Поскольку платформа выполняет вычисления и генерирует отчеты, необходимо отслеживать использование оперативной памяти. Включая метрики общего объема памяти, использованной памяти, свободной памяти и обеспечения достаточного пространства для новых задач

+ Метрики дисков: Отслеживание использования дискового пространства поможет определить, не исчерпано ли место для хранения отчетов, и предотвратить переполнение диска

+ Метрики сети: Учитывая, что взаимодействие с платформой осуществляется по протоколу HTTP, важно отслеживать метрики сетевого использования, такие как средняя загрузка сети и время отклика сервиса

+ Метрики доступности сервисов: Следует отслеживать успешность обработки запросов и время отклика сервиса, чтобы убедиться, что сервисы работают стабильно и не прекращают работу

Этот набор метрик даст нам базовое представление о производительности системы и позволит выявить возможные узкие места или проблемы, которые могут возникнуть во время эксплуатации. Они также помогут нам оптимизировать ресурсы и обеспечить высокую доступность сервисов.

#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал,
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы
можете ему предложить?

Дабы не погружать менеджера в технические особенности, можно отдельно для него вывести метрики, на основе будет складываться понимание о качестве обслуживания:

+ Среднее время ответа (Response Time): Время, которое требуется для обработки запроса пользователя и отправки ответа. Это покажет, насколько быстро система реагирует на запросы пользователей

+ Тактовая частота (Load Average): Среднее количество процессов, ожидающих выполнения в системе, за последние 1, 5 и 15 минут. Это может указывать на загруженность сервера и его способность обрабатывать запросы

+ Количество активных пользователей (Active Users): Количество одновременно подключенных пользователей, которые используют сервис. Это даст представление о нагрузке на сервер и его способности обслуживать всех пользователей

+ Ошибки и исключения (Errors and Exceptions): Количество ошибок и исключений, которые происходят в системе. Это поможет определить, сколько проблем возникает и как они влияют на обслуживание клиентов

+ Активность пользователей (User Activity Metrics): Статистика действий пользователей, таких как количество выполненных операций, частота их посещения и другие активити, связанные с использованием сервиса

Используя эти метрики, менеджер продукта сможет лучше понять, как система функционирует и какое качество обслуживания она предоставляет клиентам.
#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации,
чтобы разработчики получали ошибки приложения?

можно предложить следующие альтернативные решения:

+ Инструментирование кода: Разработчики должны быть обучены добавлять в код соответствующие записи логов, которые будут захватывать информацию о поведении приложения, ошибках и других значимых событиях в режиме реального времени

+ Использование существующих инструментов: Рассмотрите возможность использования бесплатных или открытых инструментов для сбора логов, таких как Fluentd или Logstash, которые могут автоматизировать процесс агрегации логов из различных источников

+ Централизованный логирование: Интегрируйте инструменты централизованного логирования, чтобы собирать логи из разных источников в одном месте. Это позволит разработчикам быстро находить и анализировать ошибки

+ Хранение логов: Убедитесь, что есть надежное и масштабируемое хранилище для логов, чтобы логи были доступны для анализа и отладки. Используйте облачные решения, такие как Amazon S3, Google Cloud Storage или Azure Blob Storage, для долгосрочного хранения и архивирования логов

+ Анализ логов: Позвольте разработчикам использовать инструменты для анализа логов, такие как Kibana, для поиска и фильтрации логов, что поможет быстрее находить и устранять проблемы

+ Обратная связь от пользователей: Разработайте систему обратной связи от пользователей, которая будет собирать информацию о возникающих ошибках и отправлять ее разработчикам. Это может быть простой форма обратной связи или более сложная система для сбора отчетов об ошибках

+ Аудит и мониторинг: Используйте инструменты мониторинга для отслеживания производительности приложения и выявления ошибок в реальном времени. Это поможет команде быстрее реагировать на проблемы и улучшать качество обслуживания
#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов.
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

если в нашей системе нет ни одного запроса с кодом 5xx или 4xx, это может означать, что вычисление summ_2xx_requests или summ_all_requests некорректно. Возможно, в нашей системе не учитываются некоторые типы запросов, которые фактически являются успешными.

Например:

+ Код ответа 3xx: Перенаправления, такие как 301 (Moved Permanently) или 302 (Found).

+ Код ответа 1xx: Информационные статусы, такие как 100 (Continue) или 101 (Switching Protocols).

В формулу для расчета потребуется добавить эти виды запросов.
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.

Pull модель:

Плюсы:
Быстрая реакция на проблемы, так как агенты мониторинга периодически проверяют состояние системы и отправляют данные в централизованный сервер
Подходит для долгоживущих приложений, где мониторинг необходим на протяжении всего времени работы приложения
Минусы:
Требует настройки и поддержания агентов мониторинга на всех узлах системы
Может быть сложнее в настройке и управлении, особенно в больших системах.

Push модель:

Плюсы:
Легче настроить и управлять, так как все данные собираются в одном месте и не требуют установки агентов на каждом узле
Подходит для короткоживущих приложений, которые запускаются, выполняют задачу и затем завершают работу
Минусы:
Может быть более медленной в реакции на проблемы, так как данные собираются только тогда, когда происходит событие, которое вызывает отправку данных
Требует настройки и поддержки серверов, которые принимают и обрабатывают данные мониторинга.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios

Push - TICK

Pull - Nagios

Push/Pull - Zabbix, VictoriaMetrics, Prometheus


#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк,
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`).

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.

    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

![chronograf](https://github.com/ivanmalyshev/mnt-homeworks/blob/MNT-video/10-monitoring-02-systems/chronograf.png)
![chronograf2](https://github.com/ivanmalyshev/mnt-homeworks/blob/MNT-video/10-monitoring-02-systems/chronograf2.png)
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs).
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

![chronograf_docker](https://github.com/ivanmalyshev/mnt-homeworks/blob/MNT-video/10-monitoring-02-systems/chronograf_docker.png)

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`.
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)

     ...

  + metric_N (метрика N)

- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)

    ---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
